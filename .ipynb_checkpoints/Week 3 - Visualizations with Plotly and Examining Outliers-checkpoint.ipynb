{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "voluntary-robertson",
   "metadata": {},
   "source": [
    "# Week 3: Silly goofy Visualizations + Outlier Extravaganza\n",
    "\n",
    "## This Week's Content\n",
    "This week, we will be taking it step by step and starting with some visualizations via Plotly and Matplotlib to explore the dataset (think of it like an extended EDA) a little more and get a grasp on what the data looks like from a few perspectives. I thought this was a fun one because there are so many ways data scientists can view a dataset with the literal bajillions of options to visualize something these days. Let's explore a few of them : )\n",
    "\n",
    "So the way this week will work will be that I will *attempt* to teach what each visualization is, why it may be important, ask a short coding and qualitative question, and then provide a demo for you guys!\n",
    "\n",
    "### Relevant Libraries\n",
    "[pandas](https://pandas.pydata.org/): a fast, powerful, flexible and easy to use open source data analysis and manipulation tool built on top of the Python programming language. It is one of the most common libraries used in data analysis and we will primarily be using the pandas DataFrame to manipulate our data.\n",
    "\n",
    "[numpy](https://numpy.org/): the fundamental package for scientific computing in Python. It is a Python library that provides a multidimensional array object, various derived objects (such as masked arrays and matrices), and an assortment of routines for fast operations on arrays, including mathematical, logical, shape manipulation, sorting, selecting, I/O, discrete Fourier transforms, basic linear algebra, basic statistical operations, random simulation and much more.\n",
    "\n",
    "[matplotlib](https://matplotlib.org/): a comprehensive library for creating static, animated, and interactive visualizations in Python. Many of the matplotlib functions are built into pandas DataFrames, so we will likely not have to call them directly.\n",
    "\n",
    "[plotly](https://plotly.com/python/): Plotly's Python graphing library makes interactive, publication-quality graphs. Examples of how to make line plots, scatter plots, area charts, bar charts, error bars, box plots, histograms, heatmaps, subplots, multiple-axes, polar charts, and bubble charts.\n",
    "\n",
    "[scipy](https://docs.scipy.org/doc/scipy/reference/stats.html): This module contains a large number of probability distributions, summary and frequency statistics, correlation functions and statistical tests, masked statistics, kernel density estimation, quasi-Monte Carlo functionality, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-arbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run the lines below if the code below causes an issue, you may need to download some of these pkgs\n",
    "# !pip install plotly\n",
    "# !pip install scipy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plotly.offline import init_notebook_mode, iplot, plot\n",
    "import plotly as py\n",
    "init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afraid-warehouse",
   "metadata": {},
   "source": [
    "# Now for the content!\n",
    "## First, load in our beautifully cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eligible-apache",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For some reason when we load in the data a random Unnamed column shows up, so we are gonna drop it like it's hot\n",
    "whr_data = pd.read_csv('https://github.com/shalindb/world_happiness_report/blob/main/data/cleaned_WHR_data.csv?raw=true').drop('Unnamed: 0', axis=1) \n",
    "whr_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-duplicate",
   "metadata": {},
   "source": [
    "# Scatterplots\n",
    "Let's start with a common visualization method most people have heard of and are pretty familiar with: scatterplots!\n",
    "\n",
    "To start us off, scatterplots are a type of data visualization that lets us compare two numerical variables and check for correlations (positive, negative, or neutral). Pretty simple, but these allow us to visualize things like certain correlations that we saw in an earlier week's correlation matrix, the change in happiness scores over time, etc!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural-agriculture",
   "metadata": {},
   "source": [
    "Alright, before we get into something crazy like an overlaid scatterplot (wtf is that, you may ask? I just learned about it 5 minutes ago, so we are going through this together), my task for you is to create the x and y values you'd like to use - AKA, what two features would you like to plot against each other?\n",
    "\n",
    "I have some skeleton code for you to use below, and I set up the plotly visualization below!\n",
    "Below are some hints for the ellipses. If you are stuck for too long, double click on the associated hint to get the answer : )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assumed-bradley",
   "metadata": {},
   "source": [
    "Hint for first set of ellipses: We want to find out where the Year is 2015!\n",
    "<!-- Answer: whr_data['Year'] == 2015 -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-salvation",
   "metadata": {},
   "source": [
    "Hint for second set of ellipses: We want to get the first twenty rows (Try using [this](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iloc.html))\n",
    "\n",
    "<!-- Answer: .iloc[:20, :] -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divine-reach",
   "metadata": {},
   "source": [
    "Hint for third set of ellipses: We simply want to index the feature name we are trying to get\n",
    "\n",
    "<!-- Answer: 'Feature Name' -->\n",
    "<!-- What I mean by this is that you can use any of the feature names i.e. Family, Freedom, Generosity, etc -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handed-timothy",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = whr_data.loc[...]...[...]\n",
    "\n",
    "y_data = whr_data.loc[...]...[...] # fill this out with the same exact code as above, just change your feature name!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-crawford",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = go.Scatter(  x = x_data,\n",
    "                    y = y_data,\n",
    "                    mode = \"markers\",\n",
    "                    name = \"2015\",\n",
    "                    marker = dict(color = 'blue'),\n",
    "                    #line = dict(color='firebrick', width=4, dash='dot'),\n",
    "                    text= whr_data.loc[whr_data['Year'] == 2015].Country)\n",
    "layout = dict(title = 'Happiness Rate Changing 2015 to 2019 for Top 20 Countries',\n",
    "              xaxis= dict(title= 'Family',ticklen= 5,zeroline= False),\n",
    "              yaxis= dict(title= 'Happiness',ticklen= 5,zeroline= False),\n",
    "              hovermode=\"x\"\n",
    "             )\n",
    "fig = dict(data = data, layout = layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-austin",
   "metadata": {},
   "source": [
    "Below, we will make an overlaid scatterplot of the changes in reported happiness for the top 20 countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-congo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import graph objects as \"go\"\n",
    "import plotly.graph_objs as go\n",
    "# creating trace1\n",
    "trace1 =go.Scatter(\n",
    "                    x = whr_data.loc[whr_data['Year'] == 2015].iloc[:20, :]['Country'],\n",
    "                    y = whr_data.loc[whr_data['Year'] == 2015].iloc[:20, :]['Happiness Score'],\n",
    "                    mode = \"markers\",\n",
    "                    name = \"2015\",\n",
    "                    marker = dict(color = 'red'),\n",
    "                    #line = dict(color='firebrick', width=4, dash='dot'),\n",
    "                    text= whr_data.loc[whr_data['Year'] == 2015].Country)\n",
    "# creating trace2\n",
    "trace2 =go.Scatter(\n",
    "                    x = whr_data.loc[whr_data['Year'] == 2015].iloc[:20, :]['Country'],\n",
    "                    y = whr_data.loc[whr_data['Year'] == 2016].iloc[:20, :]['Happiness Score'],\n",
    "                    mode = \"markers\",\n",
    "                    name = \"2016\",\n",
    "                    marker = dict(color = 'green'),\n",
    "                    text= whr_data.loc[whr_data['Year'] == 2016].Country)\n",
    "# creating trace3\n",
    "trace3 =go.Scatter(\n",
    "                    x = whr_data.loc[whr_data['Year'] == 2015].iloc[:20, :]['Country'],\n",
    "                    y = whr_data.loc[whr_data['Year'] == 2017].iloc[:20, :]['Happiness Score'],\n",
    "                    mode = \"markers\",\n",
    "                    name = \"2017\",\n",
    "                    marker = dict(color = 'blue'),\n",
    "                    text= whr_data.loc[whr_data['Year'] == 2017].Country)\n",
    "\n",
    "# creating trace4\n",
    "trace4 =go.Scatter(\n",
    "                    x = whr_data.loc[whr_data['Year'] == 2015].iloc[:20, :]['Country'],\n",
    "                    y = whr_data.loc[whr_data['Year'] == 2018].iloc[:20, :]['Happiness Score'],\n",
    "                    mode = \"markers\",\n",
    "                    name = \"2018\",\n",
    "                    marker = dict(color = 'black'),\n",
    "                    text= whr_data.loc[whr_data['Year'] == 2018].Country)\n",
    "\n",
    "# creating trace5\n",
    "trace5 =go.Scatter(\n",
    "                    x = whr_data.loc[whr_data['Year'] == 2015].iloc[:20, :]['Country'],\n",
    "                    y = whr_data.loc[whr_data['Year'] == 2019].iloc[:20, :]['Happiness Score'],\n",
    "                    mode = \"markers\",\n",
    "                    name = \"2019\",\n",
    "                    marker = dict(color = 'pink'),\n",
    "                    text= whr_data.loc[whr_data['Year'] == 2019].Country)\n",
    "\n",
    "\n",
    "data = [trace1, trace2, trace3, trace4, trace5]\n",
    "layout = dict(title = 'Happiness Rate Changing 2015 to 2019 for Top 20 Countries',\n",
    "              xaxis= dict(title= 'Country',ticklen= 5,zeroline= False),\n",
    "              yaxis= dict(title= 'Happiness',ticklen= 5,zeroline= False),\n",
    "              hovermode=\"x unified\"\n",
    "             )\n",
    "fig = dict(data = data, layout = layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate-friday",
   "metadata": {},
   "source": [
    "# Map Plots\n",
    "These types of plots are used to understand geographical data and allows us to understand general trends of data across the globe! They offer a bunch of different methods to utilize this visualization; however, we won't be going through all of them. \n",
    "\n",
    "We will input our data in a dictionary as follows:\n",
    "* type --> type of the map\n",
    "* colorscale --> palette\n",
    "* marker_line_width --> width of border line of countries\n",
    "* locations --> locations from dataset\n",
    "* locationmode --> locations created via country names\n",
    "* z --> The column of the graph we want to display (in our case, the feature)\n",
    "* text --> hovertext\n",
    "* colorbar --> determining colorbar\n",
    "\n",
    "All we really care about here is `z`, everything else doesn't really matter - you can choose what to put for those other values based on what you want your graph to look like. As long as you have some list of country names, you will be able to visualize those scores by region as we do below!\n",
    "\n",
    "Note: Because there are different years' data in our dataset, we would have to do a little more tweaking in order to get the averaged value over the years which may lead to a slightly different visualization. In our case, we are technically looking at values from 2015 as they are the first values that appear for a country in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-terry",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name = 'Family'\n",
    "data = dict(\n",
    "        type = 'choropleth',\n",
    "        colorscale = 'Viridis',\n",
    "         marker_line_width=1,\n",
    "        locations = whr_data['Country'],\n",
    "        locationmode = \"country names\",\n",
    "        z = whr_data[feature_name],\n",
    "        text = whr_data['Country'],\n",
    "        colorbar = {'title' : feature_name})\n",
    "\n",
    "layout = dict(title = f'Map of Global {feature_name} Values ',\n",
    "              geo = dict(projection = {'type':'mercator'}, showocean = False, showlakes = True, showrivers = True, )\n",
    "             )\n",
    "choromap = go.Figure(data = [data],layout = layout)\n",
    "iplot(choromap,validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-slide",
   "metadata": {},
   "source": [
    "### Policy Problem\n",
    "Okay, so I'm going to introduce these types of questions where I propose certain policy decisions - or ask you to propose your own - and you use your visualization to try and figure out what you'd want to implement!\n",
    "\n",
    "This first one will be a pretty easy one to get us started:\n",
    "If we were ONLY using the visualization of Happiness Scores, what c would we likely want to focus our international policy decisions on in order to have equity in everyone's happiness? (AKA which region has, on average, the lowest happiness scores?)\n",
    "\n",
    "\n",
    "\n",
    "This second one is a bit more tricky:\n",
    "Given the distribution of 'Family' values across the globe, let us choose the country with the lowest score. What policy do you believe would be the most effective and why?\n",
    "1. Offering income subsidies to the working class of this country to decrease their working hours per week\n",
    "2. Enacting children's rights laws to ensure proper education and growth for children ages 1-12\n",
    "\n",
    "Feel free to do a bit of research on this country and their position on family values, and how each of these policy decisions could impact norms in this country!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ignored-campbell",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "structural-azerbaijan",
   "metadata": {},
   "source": [
    "# Bubble Charts\n",
    "A bubble chart is a bit of a step up from a scatterplot as discussed above. Here, we can also change the size of bubbles to reflect yet another, third variable! And we can even change the color to reflect another,,, FOURTH variable! That's a lot of variables. This can be useful if we have something like our happiness score, and then multiple features that may affect that score. We can see if the largest bubbles are also largest in regards to certain features.\n",
    "Also these are some of the most aesthetically pleasing visualizations to look at, the pastel colors are all nice and pretty\n",
    "\n",
    "Our data will be input in the form:\n",
    "\n",
    "**Important:**\n",
    "* x --> x axis\n",
    "* y --> y axis\n",
    "* marker --> color represents 3rd dimension of graph, size represents 4th dimension of graph\n",
    "\n",
    "**Not as important:**\n",
    "* mode --> how points are displayed\n",
    "* name --> name of the color (i.e.: red for 2015, green for 2016..)\n",
    "* showscale --> colorbar\n",
    "* text --> Text that show when yo came on to a dot. (In this ex: Country name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coastal-marsh",
   "metadata": {},
   "source": [
    "We will be plotting two features against each other with Happiness Score as the size of the bubbles and color (this will only be 3 variables). Feel free to play around with changing this by changing the `size` and `color` attribute in the `marker` key of the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-dancing",
   "metadata": {},
   "outputs": [],
   "source": [
    "bubble_x = 'Family'\n",
    "bubble_y = 'Generosity'\n",
    "bubble_color = 'Happiness Score'\n",
    "bubble_size = 'Happiness Score'\n",
    "data = dict(y = whr_data.loc[whr_data['Year'] == 2019][bubble_x],\n",
    "            x = whr_data.loc[whr_data['Year'] == 2019][bubble_y],\n",
    "            mode = 'markers',\n",
    "            marker = {\n",
    "                'color': whr_data[bubble_color],\n",
    "                'size': whr_data[bubble_size],\n",
    "                'showscale': True,\n",
    "            },\n",
    "            text = whr_data.Country)\n",
    "\n",
    "layout = go.Layout(barmode='group', hovermode=\"x\",\n",
    "                   title=f'Bubble Chart: x = {bubble_x}, y = {bubble_y}, Size = {bubble_size}, Color = {bubble_color}, Year = 2019',\n",
    "                   xaxis=dict(title='Freedom'),\n",
    "                   yaxis=dict(title='Trust'))\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-crash",
   "metadata": {},
   "source": [
    "Conceptual understanding questions bc bubble charts can be confusing as hell\n",
    "\n",
    "1. Given:\n",
    "\n",
    "    `bubble_x = 'Family'\n",
    "    bubble_y = 'Freedom'\n",
    "    bubble_size = 'Happiness Score'\n",
    "    bubble_color = 'Happiness Score'`\n",
    "    \n",
    "If I see a small bubble with low x value and high y value, what does that mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supported-consequence",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bacterial-stations",
   "metadata": {},
   "source": [
    "2. Given:\n",
    "\n",
    "    `bubble_x = 'Family'\n",
    "    bubble_y = 'Economy'\n",
    "    bubble_size = 'Happiness Score'\n",
    "    bubble_color = 'Trust (Government Corruption)'`\n",
    "    \n",
    "If I see a large, yellow bubble with high x value and high y value, what does that mean?\n",
    "\n",
    "\n",
    "*Hint: Denmark is a country that is associated with the above characteristics*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promotional-northwest",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "informed-effectiveness",
   "metadata": {},
   "source": [
    "# Intro to Outliers\n",
    "\n",
    "What are outliers and why are they important to understand when doing data analysis? They're lil' data points that diverge from what all other data points are doing. They are the quirky ones that are out of place in what we expect the data to show. For example, let's say Health is highly correlated with Happiness Score. But what if there's a country, let's say it's called ShalinLand where they only eat Trader Joe's Frozen Pizzas because they're a monster. But what if their happiness is at its peak? It's intriguing, we're thinking how the heck is this country of insanely unhealthy maniacs still finding happiness? It lets us ask more questions and consider alternate hypotheses, etc. \n",
    "\n",
    "We can find outliers via visualizations (if you look at the visualizations above, I'm sure you can find a few points that stick out) or calculate them *mathematically*.\n",
    "\n",
    "In order to calculate the outliers, there's this process where you find the interquartile ranges, find the mean, do a lil mathematics, and out pops what you're looking for. Instead of that *slightly* annoying process, right now we can simply use the `zcore` function that the scipy library so conveniently has for us. \n",
    "\n",
    "This will calculate how far some value is from the mean/average of the data in terms of standard deviations. (If this language is confusing to you, data8 will clear it up but for now, think of it as how far a certain datapoint is from the average of all the data. If it's a certain distance away, it's considered an outlier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bulgarian-failing",
   "metadata": {},
   "source": [
    "#### Find outliers in the `whr_data` table where the absolute value of the zscore for Happiness Score is larger than 2:\n",
    "\n",
    "*Hint 1: stats.zscore(...) will return an array of zscores*\n",
    "\n",
    "*Hint 2: np.abs(...) will come in handy*\n",
    "\n",
    "*Hint 3: If we want to filter a dataframe, we can do somehting like `df[array > threshold]`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-plastic",
   "metadata": {},
   "outputs": [],
   "source": [
    "happiness_score_column = whr_data['Happiness Score']\n",
    "abs_zscores = ...\n",
    "filtered_whr_data = ...\n",
    "\n",
    "filtered_whr_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julian-abortion",
   "metadata": {},
   "source": [
    "What do you notice about these outliers? Are there more outliers that have a low happiness score or high happiness score? Try playing around with what the feature you're trying to find an outlier for to see how the outlier countries change!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charged-documentary",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "round-opinion",
   "metadata": {},
   "source": [
    "## Mahalawhat "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-advertiser",
   "metadata": {},
   "source": [
    "For multivariate datasets (i.e. we are trying to find outliers when plotting two variables against each other) we can use what is known as the Mahalanobis Distance (feel free to read up on it [here](https://towardsdatascience.com/multivariate-outlier-detection-in-python-e946cfc843b3)). This concept is incredibly out of scope for most classes you may take except for EECS 127 and CS 189. The main idea is that it finds outliers in situations where there are multiple variables. Use the above linked reading to find out more if you are interested in the math behind it. We can use this, along with scipy's `scipy.spatial.distance.mahalanobis` function in order to calculate that distance and find outliers in an n-dimensional space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "touched-complement",
   "metadata": {},
   "source": [
    "### NOTE: This next part might be slightly more challenging. Feel free to ask any questions and talk together with your partner to research the different ways to fill in the code!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-california",
   "metadata": {},
   "source": [
    "First, we want to choose two features for us to find outliers for. Then, we will find the centerpoint of the data which will allow us to do some advanced math (covariance matrix and Mahalanobis distance) in order to find out which countries are outliers for these two features specifically! Again, I highly recommend playing around with pairs of features to see what outliers you can find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-thermal",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "from scipy.stats import chi2\n",
    "\n",
    "# take two features and isolate them in the dataframe (hint: think about how to get two columns of a given dataframe)\n",
    "feat1 = 'Happiness Score'\n",
    "feat2 = 'Freedom'\n",
    "\n",
    "isolated_whr_data = whr_data.loc[whr_data['Year'] == 2019]...\n",
    "\n",
    "# find the centerpoint (hint: simply using np.mean on the dataframe will work here)\n",
    "centerpoint = ...\n",
    "print(centerpoint) # you should get [5.40709615 0.39257051]\n",
    "\n",
    "# finding covariance matrix (very out of scope)\n",
    "covariance = np.cov(isolated_whr_data, rowvar=False)\n",
    "covaraince_inv = np.linalg.matrix_power(covariance, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-medium",
   "metadata": {},
   "source": [
    "Next, we are going to create a list of tuples from the two columns we chose above. This is a pretty tricky task and requires the use of the [zip](https://www.programiz.com/python-programming/methods/built-in/zip) function in Python. Moreover, our goal should be to end up with a list of tuples that looks something like...\n",
    "\n",
    "`[(value, value), (value, value)...]`\n",
    "\n",
    "Then, we will be able to calculate the distance from our (x, y) point and the center of the data, which will give us an indication of where outliers may be!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-subscription",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_tuples = ...\n",
    "distances = []\n",
    "for feature_pair in feature_tuples:\n",
    "    distances.append(distance.mahalanobis(feature_pair, centerpoint, covaraince_inv))\n",
    "distances = np.array(distances)\n",
    "\n",
    "distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-mattress",
   "metadata": {},
   "source": [
    "Below is a bit beyond our current level of understanding, but what I'm doing here is calculating outliers based on the Chi-Square Distribution and finding them in our original dataset. Then, I am plotting a 2-D ellipse on our dataset for us to try and estimate where the outliers are. Unfortunately, Plotly hates ellipses and me so I cannot plot it the way I would've wanted to but it's okay I am definitely not emailing the CEO expressing my anger right now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-flush",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cutoff (threshold) value from Chi-Sqaure Distribution for detecting outliers \n",
    "cutoff = chi2.ppf(0.95, isolated_whr_data.shape[1]) / 2.5\n",
    "\n",
    "# Index of outliers\n",
    "outlierIndexes = np.where(distances > cutoff )\n",
    "\n",
    "\n",
    "whr_data.loc[whr_data['Year'] == 2019].iloc[outlierIndexes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-consideration",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = go.Scatter(  x = isolated_whr_data[feat1],\n",
    "                    y = isolated_whr_data[feat2],\n",
    "                    mode = \"markers\",\n",
    "                    name = \"2019\",\n",
    "                    marker = dict(color = 'blue'),\n",
    "                    #line = dict(color='firebrick', width=4, dash='dot'),\n",
    "                    text= whr_data.loc[whr_data['Year'] == 2019].Country)\n",
    "layout = dict(title = 'Happiness Rate Changing 2015 to 2019 for Top 20 Countries',\n",
    "              xaxis= dict(title= feat1,ticklen= 5,zeroline= False),\n",
    "              yaxis= dict(title= feat2,ticklen= 5,zeroline= False),\n",
    "              hovermode=\"x\"\n",
    "             )\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "\n",
    "fig.add_shape(type=\"circle\",\n",
    "    xref=\"x\", yref=\"y\",\n",
    "    x0=centerpoint[0]-lambda_[0]*np.sqrt(cutoff)*np.sqrt(2.5), y0=centerpoint[1]-lambda_[1]*np.sqrt(cutoff)*np.sqrt(2.5),\n",
    "    x1=centerpoint[0]+lambda_[0]*np.sqrt(cutoff)*np.sqrt(2.5), y1=centerpoint[1]+lambda_[1]*np.sqrt(cutoff)*np.sqrt(2.5),\n",
    "    opacity=0.2,\n",
    "    fillcolor=\"blue\",\n",
    "    line_color=\"blue\",\n",
    ")\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twenty-payday",
   "metadata": {},
   "source": [
    "Aaaaand that's all folks. Please fill out the [feedback form](https://docs.google.com/forms/d/e/1FAIpQLScmuOeOtaOq4GlLNDIDhMSMpPMxYhlgOQdP8HjBHMEsqu--VQ/viewform?usp=sf_link) once again if you have the time - thank you for coming to my ted talk"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
